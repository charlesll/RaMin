{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/charles/anaconda/envs/ml/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/charles/anaconda/envs/ml/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/charles/anaconda/envs/ml/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/charles/anaconda/envs/ml/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/charles/anaconda/envs/ml/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/charles/anaconda/envs/ml/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/charles/anaconda/envs/ml/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/charles/anaconda/envs/ml/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/charles/anaconda/envs/ml/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/charles/anaconda/envs/ml/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/charles/anaconda/envs/ml/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/charles/anaconda/envs/ml/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pickle, os\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Importation and test-valid-train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "(205, 1000)\n",
      "Shape is (205, 1000, 1)\n",
      "205 train sequences\n",
      "65 test sequences\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Data importation\n",
    "#\n",
    "print('Loading data...')\n",
    "X = np.load('./data/excellent_unoriented/obs.npy')\n",
    "y = pickle.load( open( \"./data/excellent_unoriented/labels.pkl\", \"rb\" ) )\n",
    "\n",
    "X_synth = np.load('./data/mixed_synthetic/signal_synthetic.npy')\n",
    "y = \n",
    "\n",
    "#\n",
    "# Train-Test split\n",
    "#\n",
    "X_i, X_test, y_i, y_test = train_test_split(X, y, test_size=0.20, random_state=42, shuffle=True)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_i, y_i, test_size=0.20, random_state=42, shuffle=True)\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "#\n",
    "# Reshaping\n",
    "# we need to expand to have 3D tensors as input of the 1D CNN\n",
    "\n",
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_valid = np.expand_dims(X_valid, axis=2)\n",
    "X_test = np.expand_dims(X_test, axis=2)\n",
    "\n",
    "print('Shape is {}'.format(X_train.shape))\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "nb_class = 27\n",
    "y_train = keras.utils.to_categorical(y_train, nb_class)\n",
    "y_test = keras.utils.to_categorical(y_test, nb_class)\n",
    "y_valid = keras.utils.to_categorical(y_valid, nb_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "# create the model\n",
    "model.add(Conv1D(4,2,activation='relu',kernel_initializer='glorot_uniform',input_shape=(X_train.shape[1],1)))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#model.add(Conv1D(2,2,activation='relu',kernel_initializer='glorot_uniform'))\n",
    "#model.add(MaxPooling1D())\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(100, activation='relu'))\n",
    "\n",
    "model.add(Dense(nb_class, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_11 (Conv1D)           (None, 999, 4)            12        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 499, 4)            0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 499, 4)            0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 1996)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               199700    \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 27)                2727      \n",
      "=================================================================\n",
      "Total params: 202,439\n",
      "Trainable params: 202,439\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=0)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 205 samples, validate on 52 samples\n",
      "Epoch 1/100\n",
      "205/205 [==============================] - 2s 9ms/step - loss: 2.8120 - acc: 0.2049 - val_loss: 2.1303 - val_acc: 0.5192\n",
      "Epoch 2/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 1.7272 - acc: 0.5610 - val_loss: 0.9318 - val_acc: 0.7885\n",
      "Epoch 3/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.9714 - acc: 0.7317 - val_loss: 0.4990 - val_acc: 0.8654\n",
      "Epoch 4/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.5649 - acc: 0.8634 - val_loss: 0.3876 - val_acc: 0.9231\n",
      "Epoch 5/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.3916 - acc: 0.9073 - val_loss: 0.3293 - val_acc: 0.8846\n",
      "Epoch 6/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.3327 - acc: 0.8829 - val_loss: 0.3070 - val_acc: 0.8846\n",
      "Epoch 7/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.2883 - acc: 0.9024 - val_loss: 0.3407 - val_acc: 0.8269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a57153310>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=100, batch_size=8,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation on test subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 91.22%\n",
      "Valid accuracy: 82.69%\n",
      "TestAccuracy: 90.77%\n"
     ]
    }
   ],
   "source": [
    "scores_train = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(\"Train accuracy: %.2f%%\" % (scores_train[1]*100))\n",
    "scores_valid = model.evaluate(X_valid, y_valid, verbose=0)\n",
    "print(\"Valid accuracy: %.2f%%\" % (scores_valid[1]*100))\n",
    "scores_test = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"TestAccuracy: %.2f%%\" % (scores_test[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
